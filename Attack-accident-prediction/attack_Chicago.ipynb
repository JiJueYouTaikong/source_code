{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#依赖的包\n",
    "from lib.dataloader import normal_and_generate_dataset_time, get_mask, get_adjacent, get_grid_node_map_maxtrix\n",
    "#攻击函数import\n",
    "from lib.utils_new import mask_loss, compute_loss, predict_and_evaluate, attack, random_attack, fgsm_attack, min_attack\n",
    "from lib.utils_new import saliency, saliency_loss, attack_js, attack_js,attack_saliency,rand_attack\n",
    "from model.GSNet import GSNet\n",
    "from lib.early_stop import EarlyStopping\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as Data\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "import json\n",
    "import configparser\n",
    "import pickle as pkl\n",
    "from time import time\n",
    "from datetime import datetime\n",
    "import shutil\n",
    "import argparse\n",
    "import random\n",
    "import math\n",
    "\n",
    "import sys\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_log_filename = \"test_log_ch.txt\"\n",
    "train_log_filepath = os.path.join(\"./\", train_log_filename)\n",
    "now = datetime.now()\n",
    "date_time = now.strftime(\"|%Y-%m-%d, %H:%M:%S| \")\n",
    "\n",
    "curPath = os.path.abspath(os.path.dirname('__file__'))\n",
    "rootPath = os.path.split(curPath)[0]\n",
    "sys.path.append(rootPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from mmcv import Config\n",
    "cfgin = Config.fromfile('lib/attack_all_setting.yaml')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if cfgin.dataset =='NYC':\n",
    "    config_filename = 'config/nyc/GSNet_NYC_Config.json'\n",
    "else: \n",
    "    config_filename = \"config/chicago/GSNet_Chicago_Config.json\"\n",
    "with open(config_filename, 'r') as f:\n",
    "    config = json.loads(f.read())\n",
    "\n",
    "with open(train_log_filepath, \"a\") as f:\n",
    "    f.write('测试文件运行时间：'+date_time)\n",
    "    f.write('\\r\\n')\n",
    "    f.write('超参数设置：')\n",
    "    f.write('\\r\\n')\n",
    "    f.write(json.dumps(config, sort_keys=True, indent=4))\n",
    "    f.write('\\r\\n')\n",
    "f.close\n",
    "#GPU设置\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(torch.cuda.is_available())\n",
    "\n",
    "north_south_map = config['north_south_map']\n",
    "west_east_map = config['west_east_map']\n",
    "\n",
    "all_data_filename = config['all_data_filename']\n",
    "mask_filename = config['mask_filename']\n",
    "\n",
    "road_adj_filename = config['road_adj_filename']\n",
    "risk_adj_filename = config['risk_adj_filename']\n",
    "poi_adj_filename = config['poi_adj_filename']\n",
    "grid_node_filename = config['grid_node_filename']\n",
    "grid_node_map = get_grid_node_map_maxtrix(grid_node_filename)\n",
    "num_of_vertices = grid_node_map.shape[1]\n",
    "\n",
    "\n",
    "patience = config['patience']\n",
    "delta = config['delta']\n",
    "\n",
    "if config['seed'] is not None:\n",
    "    seed = config['seed']\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "\n",
    "\n",
    "train_rate = config['train_rate']\n",
    "valid_rate = config['valid_rate']\n",
    "\n",
    "recent_prior = config['recent_prior']\n",
    "week_prior = config['week_prior']\n",
    "one_day_period = config['one_day_period']\n",
    "days_of_week = config['days_of_week']\n",
    "pre_len = config['pre_len']\n",
    "seq_len = recent_prior + week_prior\n",
    "\n",
    "training_epoch = config['training_epoch']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "learning_rate = config['learning_rate']\n",
    "\n",
    "#模型结构\n",
    "num_of_gru_layers = config['num_of_gru_layers']\n",
    "gru_hidden_size = config['gru_hidden_size']\n",
    "gcn_num_filter = config['gcn_num_filter']\n",
    "\n",
    "loaders = []\n",
    "scaler = \"\"\n",
    "train_data_shape = \"\"\n",
    "graph_feature_shape = \"\"\n",
    "   ################## #########################\n",
    "for idx, (x, y, target_times, high_x, high_y, high_target_times, scaler) in enumerate(normal_and_generate_dataset_time(\n",
    "        all_data_filename,\n",
    "        train_rate=train_rate,\n",
    "        valid_rate=valid_rate,\n",
    "        recent_prior=recent_prior,\n",
    "        week_prior=week_prior,\n",
    "        one_day_period=one_day_period,\n",
    "        days_of_week=days_of_week,\n",
    "        pre_len=pre_len)):\n",
    "    if False:#前100个，没写默认是false\n",
    "        x = x[:100]\n",
    "        y = y[:100]\n",
    "        target_times = target_times[:100]\n",
    "        high_x = high_x[:100]\n",
    "        high_y = high_y[:100]\n",
    "        high_target_times = high_target_times[:100]\n",
    "\n",
    "    if 'nyc' in all_data_filename:\n",
    "        graph_x = x[:, :, [0, 46, 47], :, :].reshape(\n",
    "            (x.shape[0], x.shape[1], -1, north_south_map*west_east_map))#4584*7*3*400\n",
    "        high_graph_x = high_x[:, :, [0, 46, 47], :, :].reshape(\n",
    "            (high_x.shape[0], high_x.shape[1], -1, north_south_map*west_east_map))#1337*7*3*400\n",
    "        graph_x = np.dot(graph_x, grid_node_map)#4584*7*3*243\n",
    "        high_graph_x = np.dot(high_graph_x, grid_node_map)\n",
    "    if 'chicago' in all_data_filename:\n",
    "        graph_x = x[:, :, [0, 39, 40], :, :].reshape(\n",
    "            (x.shape[0], x.shape[1], -1, north_south_map*west_east_map))\n",
    "        high_graph_x = high_x[:, :, [0, 39, 40], :, :].reshape(\n",
    "            (high_x.shape[0], high_x.shape[1], -1, north_south_map*west_east_map))\n",
    "        graph_x = np.dot(graph_x, grid_node_map)\n",
    "        high_graph_x = np.dot(high_graph_x, grid_node_map)\n",
    "\n",
    "    print(\"feature:\", str(x.shape), \"label:\", str(y.shape), \"time:\", str(target_times.shape),\n",
    "            \"high feature:\", str(high_x.shape), \"high label:\", str(high_y.shape))\n",
    "    print(\"graph_x:\", str(graph_x.shape),\n",
    "            \"high_graph_x:\", str(high_graph_x.shape))\n",
    "    if x.shape[0] ==1080:\n",
    "        b = np.ones_like(x)\n",
    "        b = np.where(x>1,1,0)\n",
    "\n",
    "    if idx == 0:\n",
    "        scaler = scaler\n",
    "        train_data_shape = x.shape\n",
    "        time_shape = target_times.shape\n",
    "        graph_feature_shape = graph_x.shape\n",
    "    loaders.append(Data.DataLoader(\n",
    "        Data.TensorDataset(\n",
    "            torch.from_numpy(x),\n",
    "            torch.from_numpy(target_times),#4584*32\n",
    "            torch.from_numpy(graph_x),\n",
    "            torch.from_numpy(y)\n",
    "        ),\n",
    "        batch_size=batch_size,\n",
    "        shuffle=(idx == 0)\n",
    "    ))\n",
    "    if idx == 2:\n",
    "        high_test_loader = Data.DataLoader(\n",
    "            Data.TensorDataset(\n",
    "                torch.from_numpy(high_x),\n",
    "                torch.from_numpy(high_target_times),\n",
    "                torch.from_numpy(high_graph_x),\n",
    "                torch.from_numpy(high_y)\n",
    "            ),\n",
    "            batch_size=batch_size,\n",
    "            shuffle=(idx == 0)\n",
    "        )\n",
    "train_loader, val_loader, test_loader = loaders\n",
    "################ ##################\n",
    "nums_of_filter = []\n",
    "for _ in range(2):\n",
    "    nums_of_filter.append(gcn_num_filter)\n",
    "\n",
    "GSNet_Model = GSNet(train_data_shape[2], num_of_gru_layers, seq_len, pre_len,\n",
    "                    gru_hidden_size, time_shape[1], graph_feature_shape[2],\n",
    "                    nums_of_filter, north_south_map, west_east_map)\n",
    "print(\"模型参数---------------------------------------------\")\n",
    "print(train_data_shape[2], num_of_gru_layers, seq_len, pre_len,\n",
    "        gru_hidden_size, time_shape[1], graph_feature_shape[2],\n",
    "        nums_of_filter)\n",
    "\n",
    "# multi gpu\n",
    "if torch.cuda.device_count() > 10:\n",
    "    print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\", flush=True)\n",
    "    GSNet_Model = nn.DataParallel(GSNet_Model)\n",
    "############### ######################\n",
    "GSNet_Model.to(device)\n",
    "\n",
    "GSNet_Model.load_state_dict(torch.load(\"data/model_chicago.pt\"))\n",
    "\n",
    "\n",
    "num_of_parameters = 0\n",
    "for name, parameters in GSNet_Model.named_parameters():\n",
    "    num_of_parameters += np.prod(parameters.shape)\n",
    "print(\"Number of Parameters: {}\".format(num_of_parameters), flush=True)\n",
    "\n",
    "trainer = optim.Adam(GSNet_Model.parameters(), lr=learning_rate)\n",
    "early_stop = EarlyStopping(patience=patience, delta=delta)\n",
    "\n",
    "risk_mask = get_mask(mask_filename)\n",
    "road_adj = get_adjacent(road_adj_filename)\n",
    "risk_adj = get_adjacent(risk_adj_filename)\n",
    "if poi_adj_filename == \"\":\n",
    "    poi_adj = None\n",
    "else:\n",
    "    poi_adj = get_adjacent(poi_adj_filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from lib.myfunction import get_root_logger, logger_info\n",
    "logger = get_root_logger('INFO', './logdata')\n",
    "logger.info(\"Loading config file from \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import yaml\n",
    "from mmcv import Config\n",
    "from lib.myfunction import log_test_results\n",
    "from lib.outzoom import log_test_csv,node_map\n",
    "from lib.outzoom import STZINB,min_impr,pgd_impr,random_impr,log_test_csv_time_K\n",
    "from lib.myfunction import get_root_logger, logger_info\n",
    "#配置logo\n",
    "logger = get_root_logger('INFO', './logdata')\n",
    "logger.info(\"Loading config file from \")\n",
    "\n",
    "#根据配置选择攻击方法\n",
    "if cfgin.attacker == 'white_attacker':\n",
    "    header = ['time', 'epoch', 'dataset', 'model', 'node_select', 'method', 'K', 'batch size',\n",
    "              'clean_RMSE', 'clean_recall', 'clean_MAP', 'clean_RCR',\n",
    "              'adv_RMSE', 'adv_recall', 'adv_MAP', 'adv_RCR',\n",
    "              'local_adv_RMSE', 'local_adv_recall', 'local_adv_MAP', 'local_adv_RCR',\n",
    "              '00']\n",
    "\n",
    "    file_name = 'result_chicago-data-c-{}_num-nodes{}_eps{}-model-{}'.format(\n",
    "        cfgin.dataset, cfgin.test_attack_nodes, cfgin.test_epsilon, cfgin.backbone)\n",
    "    log_test_results(cfgin.result_dir, header, file_name)\n",
    "\n",
    "    for epoch in range(5):\n",
    "        #break\n",
    "        for out_K in cfgin.K:\n",
    "            for i in cfgin.select_node:\n",
    "                for j in cfgin.attack_method:\n",
    "                    logger.info(i+'_'+j+\"_\"+str(out_K))\n",
    "                    parm_att = j  \n",
    "                    parm_node = i  \n",
    "\n",
    "                    ack_map = node_map(i,12,out_K, 5,cfgin, GSNet_Model, test_loader, risk_mask, road_adj, risk_adj, poi_adj,\n",
    "                                       grid_node_map, device, data_type='nyc')\n",
    "                    \n",
    "                    adv_val_predict, val_target, val_predict = eval(\"{0}\".format(parm_att))(logger, cfgin, ack_map, GSNet_Model, test_loader,  road_adj, risk_adj, poi_adj,\n",
    "                                                                                            grid_node_map, scaler, risk_mask, device, data_type='nyc')\n",
    "                    \n",
    "                    log_test_csv_time_K(epoch, out_K, adv_val_predict, val_target,\n",
    "                                        val_predict, cfgin, i, j, file_name, risk_mask)\n",
    "                    torch.cuda.empty_cache()\n",
    "    for epoch in range(5):\n",
    "        #break\n",
    "        for out_K in [10,20,30,40]:\n",
    "            if out_K == 40:\n",
    "                a = 12\n",
    "            else: a =47\n",
    "            i = 'HGNS'\n",
    "            j = 'STZINB'\n",
    "            logger.info(i+'_'+j+\"_\"+str(out_K))\n",
    "            parm_att = j  \n",
    "            parm_node = i  \n",
    "\n",
    "            ack_map = node_map(i, a, out_K, 5, cfgin, GSNet_Model, test_loader, risk_mask, road_adj, risk_adj, poi_adj,\n",
    "                                grid_node_map, device, data_type='chicago')\n",
    "\n",
    "            adv_val_predict, val_target, val_predict = eval(\"{0}\".format(parm_att))(logger, cfgin, ack_map, GSNet_Model, test_loader,  road_adj, risk_adj, poi_adj,\n",
    "                                                                                    grid_node_map, scaler, risk_mask, device, data_type='nyc')\n",
    "\n",
    "            log_test_csv_time_K(epoch, out_K, adv_val_predict, val_target,\n",
    "                                val_predict, cfgin, i, j, file_name, risk_mask)\n",
    "            torch.cuda.empty_cache()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2f394aca7ca06fed1e6064aef884364492d7cdda3614a461e02e6407fc40ba69"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
